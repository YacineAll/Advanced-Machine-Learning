{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exo2: Generation de séquences\n",
    "\n",
    "<h3>Binome:</h3>\n",
    "<ul>\n",
    "    <li><h4>ALLOUACHE Yacine</h4></li>\n",
    "    <li><h4>ELMAM Kenza</h4></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ce notebook sert uniquement à présenter nos résultats, et les bouts de code intéressants dans le cadre de ce rapport. L'intégralité du code est contenu dans les fichiers .py.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But\n",
    "\n",
    "<ul>\n",
    "    <li><h5>Implémenter un RNN en pytorch from scratch</h5></li>\n",
    "    <li><h5>Réaliser une classification de séquence</h5></li>    \n",
    "    <li><h5>Réaliser une tâche de forecasting (prédiction de caracètre)</h5></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données\n",
    "\n",
    "<ul>\n",
    "    <li><h4>tempAMAL</h4> <p> Un jeu de relevés de température à travers 31 villes des Etats Unis et du Canada, qui pourra servir à de la classification de séquence (many to one), par exemple pour prédire une ville sachant une séquence de température, ou à du forecasting, en préduisant la température à ${t+1}$.</p></li>\n",
    "        <li><h4>trump_full_speech</h4> <p> C'est le speech de Trump, le président americain, c'est un jeu de données textuelle, qui pourra servir essentiellement pour la generation de sequence</p></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os \n",
    "from datetime import datetime\n",
    "\n",
    "import string\n",
    "import unicodedata\n",
    "import unidecode\n",
    "import re\n",
    "\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exo4 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_attributes.csv\n",
      "shakespeare.txt\n",
      "tempAMAL_test.csv\n",
      "tempAMAL_train.csv\n",
      "trump_full_speech.txt\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = f\"{'./experiments'}/exo4\"     \n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "log_dir = f\"{'./checkpoints'}/exo4\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_path = f'{checkpoint_dir}/checkpoint_' + datetime.now().strftime('%d_%m_%Y_%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/trump_full_speech.txt\" \n",
    "BATCH_SIZE= 16\n",
    "LATENT_SIZE = 10\n",
    "LR = 1e-3\n",
    "N_EPOCHS = 10\n",
    "with open(f'{data_path}') as f:\n",
    "    text = f.read()\n",
    "text = text #[0]+text[1]+text[2]+text[3]\n",
    "text = unidecode.unidecode(text)\n",
    "text = unicodedata.normalize('NFD', text)\n",
    "text = text.lower()\n",
    "text = text.translate(str.maketrans(\"\",\"\", re.sub('[\\.|,|;]', '', string.punctuation)))\n",
    "text = text.strip()\n",
    "LETTRES = set(text)\n",
    "id2lettre = dict(zip(range(1,len(LETTRES)+1),LETTRES))\n",
    "lettre2id = dict(zip(id2lettre.values(),id2lettre.keys()))\n",
    "X = string2code(text, lettre2id).astype(np.float32)\n",
    "N_LETTRES = len(LETTRES)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datset_diff = TextDataset(X)\n",
    "trainloader_diff = torch.utils.data.DataLoader(train_datset_diff, batch_size=BATCH_SIZE, shuffle=True, collate_fn=func(train_datset_diff))\n",
    "model = Rnn_Generator(input_size=1, latent_size=LATENT_SIZE, output=N_LETTRES).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Loss: 3.6222: 100%|██████████| 10/10 [1:47:07<00:00, 642.80s/it]\n"
     ]
    }
   ],
   "source": [
    "l = train(\n",
    "        train=trainloader_diff, \n",
    "        model=model, \n",
    "        criterion=criterion, \n",
    "        optimizer=optimizer, \n",
    "        n_lettres=N_LETTRES, \n",
    "        n_epochs=N_EPOCHS, \n",
    "        log_dir=log_dir, \n",
    "        checkpoint_path=checkpoint_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(model, start, n_lettres, length, temperature, lettre2id, id2lettre):\n",
    "    with torch.no_grad():\n",
    "        start = torch.from_numpy(np.array([lettre2id[start]]).astype(np.float32))\n",
    "        h = model.initHidden()\n",
    "        l = []\n",
    "        for _ in range(length):\n",
    "            h = model.one_step(start, h)\n",
    "            out = model.decode(h.unsqueeze(0))\n",
    "            \n",
    "            #\n",
    "            output_dist = out.data.view(-1).div(temperature).exp()\n",
    "            nex = torch.multinomial(output_dist, 1)[0]\n",
    "            #\n",
    "            \n",
    "            # nex =  np.random.choice(np.arange(n_lettres), p=torch.flatten(out).numpy())\n",
    "\n",
    "            start = nex.view(-1,1).float() #torch.from_numpy(np.array([nex]).astype(np.float32))\n",
    "            print(nex)\n",
    "            l.append(id2lettre[nex.item()+1])\n",
    "        return \"\".join(l)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(35)\n",
      "tensor(8)\n",
      "tensor(25)\n",
      "tensor(33)\n",
      "tensor(4)\n",
      "tensor(34)\n",
      "tensor(39)\n",
      "tensor(25)\n",
      "tensor(38)\n",
      "tensor(29)\n",
      "tensor(41)\n",
      "tensor(40)\n",
      "tensor(29)\n",
      "tensor(30)\n",
      "tensor(40)\n",
      "tensor(5)\n",
      "tensor(17)\n",
      "tensor(25)\n",
      "tensor(9)\n",
      "tensor(5)\n",
      "tensor(35)\n",
      "tensor(10)\n",
      "tensor(31)\n",
      "tensor(4)\n",
      "tensor(9)\n",
      "tensor(8)\n",
      "tensor(14)\n",
      "tensor(23)\n",
      "tensor(24)\n",
      "tensor(31)\n",
      "tensor(13)\n",
      "tensor(32)\n",
      "tensor(35)\n",
      "tensor(25)\n",
      "tensor(16)\n",
      "tensor(5)\n",
      "tensor(7)\n",
      "tensor(24)\n",
      "tensor(9)\n",
      "tensor(31)\n",
      "tensor(8)\n",
      "tensor(37)\n",
      "tensor(25)\n",
      "tensor(23)\n",
      "tensor(31)\n",
      "tensor(8)\n",
      "tensor(19)\n",
      "tensor(8)\n",
      "tensor(5)\n",
      "tensor(35)\n",
      "tensor(3)\n",
      "tensor(17)\n",
      "tensor(25)\n",
      "tensor(2)\n",
      "tensor(17)\n",
      "tensor(6)\n",
      "tensor(11)\n",
      "tensor(24)\n",
      "tensor(19)\n",
      "tensor(22)\n",
      "tensor(38)\n",
      "tensor(22)\n",
      "tensor(3)\n",
      "tensor(29)\n",
      "tensor(27)\n",
      "tensor(3)\n",
      "tensor(8)\n",
      "tensor(29)\n",
      "tensor(39)\n",
      "tensor(41)\n",
      "tensor(41)\n",
      "tensor(17)\n",
      "tensor(42)\n",
      "tensor(37)\n",
      "tensor(5)\n",
      "tensor(11)\n",
      "tensor(5)\n",
      "tensor(17)\n",
      "tensor(12)\n",
      "tensor(36)\n",
      "tensor(5)\n",
      "tensor(9)\n",
      "tensor(20)\n",
      "tensor(26)\n",
      "tensor(11)\n",
      "tensor(27)\n",
      "tensor(19)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(20)\n",
      "tensor(21)\n",
      "tensor(34)\n",
      "tensor(26)\n",
      "tensor(35)\n",
      "tensor(0)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-0562aeee802a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_LETTRES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlettre2id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2lettre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-6a0bd0e792f3>\u001b[0m in \u001b[0;36mgenerate_sequence\u001b[0;34m(model, start, n_lettres, length, temperature, lettre2id, id2lettre)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#torch.from_numpy(np.array([nex]).astype(np.float32))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid2lettre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "print(generate_sequence(model, \"p\", N_LETTRES, 100, .7, lettre2id, id2lettre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bita4774d6f44b14c908c5f5fa0bfb95dd2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
