{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#from tp1_descente import *\n",
    "from tp1 import MSE, Linear, Context\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(50, 13, requires_grad=True)\n",
    "y = torch.randn(50, 3)\n",
    "\n",
    "\n",
    "# Les paramètres du modèle à optimiser\n",
    "w = torch.randn(13, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = Linear.apply\n",
    "mse = MSE.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itérations 0: loss 39.51331329345703\n",
      "Itérations 1: loss 37.72736358642578\n",
      "Itérations 2: loss 34.37503433227539\n",
      "Itérations 3: loss 29.8647403717041\n",
      "Itérations 4: loss 24.736711502075195\n",
      "Itérations 5: loss 19.58844566345215\n",
      "Itérations 6: loss 14.993562698364258\n",
      "Itérations 7: loss 11.426044464111328\n",
      "Itérations 8: loss 9.200835227966309\n",
      "Itérations 9: loss 8.43909740447998\n",
      "Itérations 10: loss 9.062490463256836\n",
      "Itérations 11: loss 10.816438674926758\n",
      "Itérations 12: loss 13.317907333374023\n",
      "Itérations 13: loss 16.119571685791016\n",
      "Itérations 14: loss 18.7801513671875\n",
      "Itérations 15: loss 20.929927825927734\n",
      "Itérations 16: loss 22.32161521911621\n",
      "Itérations 17: loss 22.859560012817383\n",
      "Itérations 18: loss 22.60347557067871\n",
      "Itérations 19: loss 21.747638702392578\n",
      "Itérations 20: loss 20.579565048217773\n",
      "Itérations 21: loss 19.425922393798828\n",
      "Itérations 22: loss 18.59470558166504\n",
      "Itérations 23: loss 18.32314109802246\n",
      "Itérations 24: loss 18.739355087280273\n",
      "Itérations 25: loss 19.843477249145508\n",
      "Itérations 26: loss 21.510417938232422\n",
      "Itérations 27: loss 23.512924194335938\n",
      "Itérations 28: loss 25.56056022644043\n",
      "Itérations 29: loss 27.34765625\n",
      "Itérations 30: loss 28.602203369140625\n",
      "Itérations 31: loss 29.128002166748047\n",
      "Itérations 32: loss 28.833417892456055\n",
      "Itérations 33: loss 27.74293327331543\n",
      "Itérations 34: loss 25.990339279174805\n",
      "Itérations 35: loss 23.7954044342041\n",
      "Itérations 36: loss 21.42848777770996\n",
      "Itérations 37: loss 19.169198989868164\n",
      "Itérations 38: loss 17.2658748626709\n",
      "Itérations 39: loss 15.902084350585938\n",
      "Itérations 40: loss 15.17507266998291\n",
      "Itérations 41: loss 15.08869457244873\n",
      "Itérations 42: loss 15.561144828796387\n",
      "Itérations 43: loss 16.44523048400879\n",
      "Itérations 44: loss 17.557207107543945\n",
      "Itérations 45: loss 18.70895767211914\n",
      "Itérations 46: loss 19.7381591796875\n",
      "Itérations 47: loss 20.531742095947266\n",
      "Itérations 48: loss 21.03920555114746\n",
      "Itérations 49: loss 21.274362564086914\n",
      "Itérations 50: loss 21.305971145629883\n",
      "Itérations 51: loss 21.23944854736328\n",
      "Itérations 52: loss 21.193267822265625\n",
      "Itérations 53: loss 21.27431869506836\n",
      "Itérations 54: loss 21.5562744140625\n",
      "Itérations 55: loss 22.064579010009766\n",
      "Itérations 56: loss 22.770204544067383\n",
      "Itérations 57: loss 23.592960357666016\n",
      "Itérations 58: loss 24.413583755493164\n",
      "Itérations 59: loss 25.092470169067383\n",
      "Itérations 60: loss 25.49201202392578\n",
      "Itérations 61: loss 25.499027252197266\n",
      "Itérations 62: loss 25.04397964477539\n",
      "Itérations 63: loss 24.11418914794922\n",
      "Itérations 64: loss 22.759122848510742\n",
      "Itérations 65: loss 21.087249755859375\n",
      "Itérations 66: loss 19.254779815673828\n",
      "Itérations 67: loss 17.447959899902344\n",
      "Itérations 68: loss 15.861188888549805\n",
      "Itérations 69: loss 14.673785209655762\n",
      "Itérations 70: loss 14.02821159362793\n",
      "Itérations 71: loss 14.01248836517334\n",
      "Itérations 72: loss 14.648738861083984\n",
      "Itérations 73: loss 15.889348983764648\n",
      "Itérations 74: loss 17.621068954467773\n",
      "Itérations 75: loss 19.676708221435547\n",
      "Itérations 76: loss 21.85310173034668\n",
      "Itérations 77: loss 23.933429718017578\n",
      "Itérations 78: loss 25.711326599121094\n",
      "Itérations 79: loss 27.014135360717773\n",
      "Itérations 80: loss 27.722633361816406\n",
      "Itérations 81: loss 27.784719467163086\n",
      "Itérations 82: loss 27.22139549255371\n",
      "Itérations 83: loss 26.12413215637207\n",
      "Itérations 84: loss 24.64352035522461\n",
      "Itérations 85: loss 22.970436096191406\n",
      "Itérations 86: loss 21.31194305419922\n",
      "Itérations 87: loss 19.864587783813477\n",
      "Itérations 88: loss 18.788776397705078\n",
      "Itérations 89: loss 18.1875\n",
      "Itérations 90: loss 18.092626571655273\n",
      "Itérations 91: loss 18.460826873779297\n",
      "Itérations 92: loss 19.180152893066406\n",
      "Itérations 93: loss 20.086666107177734\n",
      "Itérations 94: loss 20.989164352416992\n",
      "Itérations 95: loss 21.698585510253906\n",
      "Itérations 96: loss 22.058002471923828\n",
      "Itérations 97: loss 21.968517303466797\n",
      "Itérations 98: loss 21.40713882446289\n",
      "Itérations 99: loss 20.433422088623047\n"
     ]
    }
   ],
   "source": [
    "for n_iter in range(100):\n",
    "    ##  TODO:  Calcul du forward (loss)\n",
    "\n",
    "    # `loss` doit correspondre au coût MSE calculé à cette itération\n",
    "    # on peut visualiser avec\n",
    "    # tensorboard --logdir runs/\n",
    "    y_hat = linear(x, w, b)\n",
    "    loss = mse(y_hat, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    writer.add_scalar('Loss/train', loss, n_iter)\n",
    "    # Sortie directe\n",
    "    print(f\"Itérations {n_iter}: loss {loss}\")\n",
    "        \n",
    "    # Calcul du backward (grad_w, grad_b)\n",
    "    grad_x, grad_w, grad_b = x.grad, w.grad, b.grad\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ## Mise à jour des paramètres du modèle\n",
    "        w -=  0.01 * grad_w\n",
    "        b -=  0.01 * grad_b\n",
    "    \n",
    "    #w.requires_grad_(True)\n",
    "    #b.requires_grad_(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bita4774d6f44b14c908c5f5fa0bfb95dd2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
