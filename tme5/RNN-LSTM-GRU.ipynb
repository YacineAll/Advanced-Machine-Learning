{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"RNN-LSTM-GRU.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"HUMv352NkFE-"},"source":["# TP 5 LTSM, GRU, et autres cellules à mémoire\n","Dans ce TP, nous étudierons deux problèmes :\n","\n","1. Comment traiter et générer des séquences de taille variable ?\n","2. Comment prendre en compte des dépendances à plus long terme (Vanishing/exploding gradients)\n","\n","Pour la génération de séquences, on travaillera sur le jeu de données (discours pré-électoraux de Trump).\n","\n","Nous allons étudier des variantes des RNNs, et en particulier les Long-Short\n","Term Memories/LSTMs [2] et les Gated Recurrent Units/GRU\n","\n","\n","## Notable TODOs:\n","- 1 Génération de séquences de taille variable\n","- 2 Prise en compte de dépendences lointaines : LSTM et GRU\n","- 3 Beam-search\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fKNVZCIFkFE_"},"source":["# Setup\n","\n","## Library import\n","Nous importons toutes les bibliothèques Python nécessaires"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZCEuTI2kJLr","executionInfo":{"status":"ok","timestamp":1608160206264,"user_tz":-60,"elapsed":25049,"user":{"displayName":"Kenza ELMAM","photoUrl":"","userId":"10901048916499628836"}},"outputId":"8421f826-482d-413c-c56d-0c6f3d2018ec"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":33},"id":"bGFFGreWkFFA","executionInfo":{"status":"ok","timestamp":1608160210683,"user_tz":-60,"elapsed":2510,"user":{"displayName":"Kenza ELMAM","photoUrl":"","userId":"10901048916499628836"}},"outputId":"b796a09c-baeb-4810-bec7-d1d4ba52173e"},"source":["# Data manipulation\n","import pandas as pd\n","import numpy as np\n","\n","\n","# Options for pandas\n","pd.options.display.max_columns = 50\n","pd.options.display.max_rows = 30\n","\n","# Visualizations\n","import plotly\n","import plotly.graph_objs as go\n","import plotly.offline as ply\n","plotly.offline.init_notebook_mode(connected=True)\n","\n","import cufflinks as cf\n","cf.go_offline(connected=True)\n","cf.set_config_file(theme='white')\n","\n","import matplotlib as plt\n","import os\n","from datetime import datetime\n","# Autoreload extension\n","if 'autoreload' not in get_ipython().extension_manager.loaded:\n","    %load_ext autoreload\n","    \n","%autoreload 2"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"EJsnc6s6kFFE"},"source":["## Local library import\n","Nous importons toutes les bibliothèques locales nécessaires"]},{"cell_type":"code","metadata":{"id":"Vd_k3CnDkFFE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608160221759,"user_tz":-60,"elapsed":7127,"user":{"displayName":"Kenza ELMAM","photoUrl":"","userId":"10901048916499628836"}},"outputId":"b3d2aaf2-a0d4-4410-ac80-71d2b9f9f2bc"},"source":["# Include local library paths\n","import nltk\n","import re\n","\n","import sys\n","sys.path.append(\"./drive/MyDrive/amal/tme5/src\") # uncomment and fill to import local libraries\n","\n","from textloader import *\n","from tp5 import *\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-lPqxUAdtkBQ","executionInfo":{"status":"ok","timestamp":1608154237154,"user_tz":-60,"elapsed":3084,"user":{"displayName":"Kenza ELMAM","photoUrl":"","userId":"10901048916499628836"}},"outputId":"26355ea6-abf3-4962-95b4-724b3e81ab4e"},"source":["print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"epFYxPMwTz39"},"source":["# 1. Implementation et expérimentation de LSTM \n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8nw9kWOTU1gF"},"source":["Avec Les RNN, Lorsque la séquence à traiter est trop longue, la rétropropagation du gradient de l’erreur peut soit devenir beaucoup trop grande et exploser, soit au contraire devenir beaucoup trop petite. Le réseau ne fait alors plus la différence entre une information qu’il doit prendre en compte ou non. Il se trouve ainsi dans l’incapacité d’apprendre à long terme.\n","\n","Les LSTM (Long short-term memory) proposent une solution à ce problème en prenant en compte un vecteur mémoire via un système de portes (gates) et d’états.\n","\n","\n","<img src=\"./drive/MyDrive/amal/tme5/img/lstm.png\" style=\"display:block;margin-left:auto;margin-right:auto;width:50%;\"> <br>"]},{"cell_type":"markdown","metadata":{"id":"MhcavX-fkFFF"},"source":["## Parameter definition\n","Nous fixons tous les paramètres pertinents pour notre notebook. Par convention\n","les paramètres sont en majuscules, tandis que toutes les autres variables suivent les directives de Python.\n","\n"]},{"cell_type":"code","metadata":{"id":"gcBO2GuWNUDC"},"source":["lr = 1e-3\n","batch_size=64\n","n_epochs = 10\n","num_embeddings=len(id2lettre)\n","embedding_dim=200\n","hidden_size=200\n","output_size=len(id2lettre)\n","\n","\n","\n","log_dir = \"./drive/MyDrive/amal/tme5/experiments/lstm\"\n","checkpoint_dir = './checkpoints/lstm'\n","checkpoint_path = f'{checkpoint_dir}/checkpoint_same_l_' + \\\n","            datetime.now().strftime('%d_%m_%Y_%H:%M:%S')\n","\n","os.makedirs(f\"{log_dir}\", exist_ok=True)\n","os.makedirs(f\"{checkpoint_dir}\", exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kWmAJweGkFFF"},"source":["\n","## Data import\n","Nous récupérons toutes les données nécessaires à l'analyse."]},{"cell_type":"code","metadata":{"id":"fSa8hHqjkFFF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608160238464,"user_tz":-60,"elapsed":2007,"user":{"displayName":"Kenza ELMAM","photoUrl":"","userId":"10901048916499628836"}},"outputId":"d136ff1c-4eee-471c-fa12-8c924643f21b"},"source":["nltk.download('punkt')\n","data_path = \"./drive/MyDrive/amal/tme5/data/trump_full_speech.txt\"\n","with open(f'{data_path}') as f:\n","    text = f.read()\n","text = text.strip()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iZF70wFOObjQ"},"source":["## Creation du dataset et dataLoader\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"w8WpaoHBOV8Z"},"source":["traindataset = TextDataset(text)\n","trainloader = DataLoader(traindataset, batch_size=32, collate_fn=collate_fn, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISYjVmeRkFFF"},"source":["from tqdm import tqdm\n","\n","class LSTM(nn.Module):\n","    def __init__(self, num_embeddings, embedding_dim, hidden_size, output_size):\n","        super(LSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embeddings = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim)\n","        \n","        self.f = nn.Linear(embedding_dim + hidden_size, hidden_size)\n","        self.i = nn.Linear(embedding_dim + hidden_size, hidden_size)\n","        self.c = nn.Linear(embedding_dim + hidden_size, hidden_size)\n","\n","        self.o = nn.Linear(embedding_dim + hidden_size, hidden_size)\n","    \n","        self.out = nn.Sequential(nn.Linear(hidden_size, output_size), nn.LogSoftmax(dim=1))\n","\n","    def forward(self, x, h, c):\n","        x = self.embeddings(x).squeeze(1)\n","        input_combined = torch.cat((x, h), 1)\n","\n","        ft = torch.sigmoid(self.f(input_combined))\n","        it = torch.sigmoid(self.i(input_combined))\n","        ct = ft*c + it*torch.tanh(self.c(input_combined))\n","        ot = torch.sigmoid(self.o(input_combined))\n","\n","        ht = ot*torch.tanh(ct)\n","        return ht, ct\n","\n","    def decode(self, ht):\n","        return self.out(ht)\n","\n","    def initHidden(self, n):\n","        return torch.zeros(n, self.hidden_size), torch.zeros(n, self.hidden_size) \n","\n","class MaskedCrossEntropy(nn.Module):\n","    def __init__(self):\n","        super(MaskedCrossEntropy, self).__init__()\n","\n","    def forward(self, logit, target, mask):\n","        loss = F.nll_loss(logit, target, reduction='none')\n","        loss *= mask\n","        return loss.sum() / mask.sum()\n","\n","def train_step(state,model, criterion, x, y, m):\n","    x.unsqueeze_(-1)\n","    h = [ t.to(device) for t in state.model.initHidden(x.shape[1])]\n","    loss = 0\n","    for i, x in enumerate(x):\n","        h = state.model(x, *h)\n","        logits = state.model.decode(h[0])\n","        loss += criterion(logits, y[i], m[i])\n","    return loss\n","\n","\n","def train(train, model, criterion, optimizer, scheduler, n_epochs, log_dir, checkpoint_path):\n","    losses = []\n","    writer = SummaryWriter(log_dir=log_dir)\n","    pbar = tqdm(range(n_epochs), total=n_epochs, file=sys.stdout)\n","    state = load_state(checkpoint_path, model, optimizer)\n","\n","    for i in pbar:\n","          l = []\n","          for x in train:\n","              x, y, m = x[:-1].to(device), x[1:].to(device), (x[1:]!=PAD_IX ).to(device)\n","\n","              loss = train_step(state,model, criterion, x, y, m)\n","              state.optimizer.zero_grad()\n","              loss.backward()            \n","              state.optimizer.step()\n","              l.append(loss.item()/len(x))\n","              state.iteration += 1\n","          \n","          state.epoch +=1\n","          save_state(checkpoint_path, state)\n","\n","          #scheduler.step()\n","          lo = np.mean(l)\n","          losses.append(lo)\n","\n","          writer.add_scalar('Loss/train', lo, i)\n","\n","          pbar.set_description(f'Train: Loss: {np.round(lo, 4)}') # \\tTest: Loss: {np.round(test_lo, 4)}\n","          pbar.update()\n","\n","    return losses\n","\n","class State:\n","    def __init__(self, model, optimizer):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.epoch, self.iteration = 0, 0\n","\n","\n","def save_state(checkpoint_path, state):\n","    savepath = Path(f\"{checkpoint_path}\")\n","    with savepath.open(\"wb\") as f:\n","        torch.save(state, f)\n","\n","def load_state(checkpoint_path, model, optimizer):\n","    savepath = Path(f\"{checkpoint_path}\")\n","    if savepath.is_file():\n","        with savepath.open(\"rb\") as f:\n","            state = torch.load(f)\n","            return state\n","    return State(model, optimizer)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pj7DFdeRPZzq"},"source":["## Definition de notre modele, optimizer, et la loss \n","\n","\n","\n","\n","---\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"G0ND-DVNtKjq","executionInfo":{"status":"error","timestamp":1608162832101,"user_tz":-60,"elapsed":2029254,"user":{"displayName":"Kenza ELMAM","photoUrl":"","userId":"10901048916499628836"}},"outputId":"457c2966-a0bf-401e-aa33-a7aa1b9cd99c"},"source":["model = LSTM(num_embeddings=num_embeddings, embedding_dim=embedding_dim, hidden_size=hidden_size, output_size=output_size).to(device)\n","criterion = MaskedCrossEntropy()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","losses = train(\n","        train=trainloader, \n","        model=model, \n","        criterion=criterion, \n","        optimizer=optimizer, \n","        scheduler = None,\n","        n_epochs=n_epochs, \n","        #device=device,\n","        log_dir=log_dir, \n","        checkpoint_path=checkpoint_path\n","    )\n","\n","torch.save(model.state_dict(), \"./drive/MyDrive/tme5/model-lstm-fitted.pth\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Train: Loss: 2.1753:   0%|          | 0/10 [03:36<?, ?it/s]\u001b[A\u001b[A\n","\n","Train: Loss: 2.1753:  10%|█         | 1/10 [03:36<32:24, 216.03s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 2.1753:  10%|█         | 1/10 [03:36<32:24, 216.04s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.7024:  10%|█         | 1/10 [07:00<32:24, 216.04s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.7024:  20%|██        | 2/10 [07:00<28:19, 212.48s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.7024:  20%|██        | 2/10 [07:00<28:19, 212.48s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.5232:  20%|██        | 2/10 [10:21<28:19, 212.48s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.5232:  30%|███       | 3/10 [10:21<24:24, 209.19s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.5232:  30%|███       | 3/10 [10:21<24:24, 209.20s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.4188:  30%|███       | 3/10 [13:42<24:24, 209.20s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.4188:  40%|████      | 4/10 [13:42<20:39, 206.62s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.4188:  40%|████      | 4/10 [13:42<20:39, 206.62s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.3519:  40%|████      | 4/10 [17:03<20:39, 206.62s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.3519:  50%|█████     | 5/10 [17:03<17:04, 204.92s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.3519:  50%|█████     | 5/10 [17:03<17:04, 204.92s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.3002:  50%|█████     | 5/10 [20:26<17:04, 204.92s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.3002:  60%|██████    | 6/10 [20:27<13:38, 204.55s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.3002:  60%|██████    | 6/10 [20:27<13:38, 204.55s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.2589:  60%|██████    | 6/10 [23:47<13:38, 204.55s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.2589:  70%|███████   | 7/10 [23:47<10:09, 203.31s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.2589:  70%|███████   | 7/10 [23:47<10:09, 203.31s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.2268:  70%|███████   | 7/10 [27:08<10:09, 203.31s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.2268:  80%|████████  | 8/10 [27:08<06:45, 202.53s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.2268:  80%|████████  | 8/10 [27:08<06:45, 202.53s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.1975:  80%|████████  | 8/10 [30:28<06:45, 202.53s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.1975:  90%|█████████ | 9/10 [30:28<03:21, 201.90s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.1975:  90%|█████████ | 9/10 [30:28<03:21, 201.90s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.1748:  90%|█████████ | 9/10 [33:48<03:21, 201.90s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.1748: 100%|██████████| 10/10 [33:48<00:00, 201.33s/it]\u001b[A\u001b[A\n","\n","Train: Loss: 1.1748: 100%|██████████| 10/10 [33:48<00:00, 202.85s/it]\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-88658fe33010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./drive/MyDrive/tme5/model-lstm-fitted.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './drive/MyDrive/tme5/model-lstm-fitted.pth'"]}]},{"cell_type":"code","metadata":{"id":"cUSkj2s7tKl6","colab":{"base_uri":"https://localhost:8080/","height":837},"executionInfo":{"status":"ok","timestamp":1608159497986,"user_tz":-60,"elapsed":4752,"user":{"displayName":"Kenza ELMAM","photoUrl":"","userId":"10901048916499628836"}},"outputId":"cadc3583-3e69-45fd-a675-1a10d5893e97"},"source":["%load_ext tensorboard\n","%tensorboard --logdir ./experiments/lstm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"fOqVxbtv0kI2","executionInfo":{"status":"error","timestamp":1608160466050,"user_tz":-60,"elapsed":4795,"user":{"displayName":"Kenza ELMAM","photoUrl":"","userId":"10901048916499628836"}},"outputId":"785359e4-e449-470d-9836-6b0e304e2e96"},"source":["model = LSTM(num_embeddings=num_embeddings, embedding_dim=embedding_dim, hidden_size=hidden_size, output_size=output_size).to(device)\n","criterion = MaskedCrossEntropy()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","losses = train(\n","        train=trainloader, \n","        model=model, \n","        criterion=criterion, \n","        optimizer=optimizer, \n","        scheduler = None,\n","        n_epochs=n_epochs, \n","        log_dir=log_dir, \n","        checkpoint_path=checkpoint_path\n","    )\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-7a8eb238c15e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/amal/tme5/src/tp5.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train, model, criterion, optimizer, scheduler, n_epochs, log_dir, checkpoint_path)\u001b[0m\n\u001b[1;32m    147\u001b[0m           \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m               \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mPAD_IX\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"H0OxzYacqti_"},"source":["## Génération de séquences  à l'aide de LSTM \n"]},{"cell_type":"code","metadata":{"id":"lqnVjD9TtKsw"},"source":["model.load_state_dict(torch.load(\"./drive/MyDrive/tme5/model-lstm-fitted.pth\"))\n","model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PuW4AUZbtKxb"},"source":["def generate(model, start, maxlength):\n","    x = torch.tensor(string2code(start)).unsqueeze(-1).to(device)\n","    h = [ v.to(device) for v in model.initHidden(1)]\n","    l = [lettre2id[start]]\n","    model.eval()\n","    predictions = []\n","    with torch.no_grad():\n","        for i in range(maxlength):\n","            h = model(x, *h) #h = model.one_step(x, *h)\n","            d = model.decode(h[0])\n","            predictions.append(d.squeeze(0).tolist())\n","            probs = torch.exp(d)\n","            start = torch.distributions.categorical.Categorical(probs).sample()\n","            l.append(start.item())\n","            if start.item() == EOS_IX:\n","                break\n","            start = start.unsqueeze(-1).to(device)\n","    return code2string(l), predictions\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"eECi3BdFtK1g","executionInfo":{"status":"ok","timestamp":1608160027860,"user_tz":-60,"elapsed":725,"user":{"displayName":"Kenza ELMAM","photoUrl":"","userId":"10901048916499628836"}},"outputId":"e6c77fb3-1dd5-49e1-ea38-f89aad263a5b"},"source":["string, predictions = generate(model, \"W\", 100)\n","string"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'W0[\\\\KT+vo71mZ|9::{icL9c#l))h#T#cj(q;LC[*<.$x1:0g 7?\\'75#l\":CH~3Q>C^t<HRUtI2su(9ja|+g_hXiV-\"2,7]VL\\'.Wk'"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"K2vy5iqvkFFH"},"source":["model = LSTM(num_embeddings=len(id2lettre), embedding_dim=200, hidden_size=300, output_size=len(id2lettre)).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = MaskedCrossEntropy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":184},"id":"5LjjXk42kFFH","executionInfo":{"status":"error","timestamp":1608160036653,"user_tz":-60,"elapsed":1145,"user":{"displayName":"Kenza ELMAM","photoUrl":"","userId":"10901048916499628836"}},"outputId":"e5675bfb-86b4-40cd-cc5c-c53e076c4c51"},"source":["losses = train(trainloader, model, criterion, optimizer, None, 100,log_dir,checkpoint_path)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-4ef9d1f88931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: train() missing 2 required positional arguments: 'log_dir' and 'checkpoint_path'"]}]},{"cell_type":"code","metadata":{"id":"wr15ox_pkFFI","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1608160048483,"user_tz":-60,"elapsed":733,"user":{"displayName":"Kenza ELMAM","photoUrl":"","userId":"10901048916499628836"}},"outputId":"4752e511-dbcb-4a2c-8553-9b0924d32e74"},"source":["string, predictions = generate(model, \"I\", 100)\n","string"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"InD'G !b5iQHyM5:itx&Jj4zAiRl*SX{X9uQ]o,`$jvb+}GLHutUA&';9Zqy7gM%3]|\""]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"7109fmqjrVzv"},"source":["# 2. Implementation et éxperimentation  de GRU \n","\n","Une variante des LSTM sont les GRU (Gated Recurrent Unit). Cette structure est plus simple que les LSTM au sens où moins de paramètres entrent en jeu.e, les portes entrée/oubli sont fusionnées Le nombre de portes passe à 2 et celui d’état à 1\n","\n","<img src=\"./drive/MyDrive/amal/tme5/img/GRU.png\" style=\"display:block;margin-left:auto;margin-right:auto;width:50%;\"> <br>\n"]},{"cell_type":"code","metadata":{"id":"BMGwe81K3Clf"},"source":["model = GRU(num_embeddings=len(id2lettre), embedding_dim=100, hidden_size=150, output_size=len(id2lettre))\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = MaskedCrossEntropy()\n","losses = train(trainloader, model, criterion, optimizer, None, 20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vCtlaUYXkFFK"},"source":["def generate(model, start, maxlength):\n","    x = torch.tensor(string2code(start)).unsqueeze(-1).to(device)\n","    h = [ v.to(device) for v in model.initHidden(1)]\n","    l = [lettre2id[start]]\n","    model.eval()\n","    predictions = []\n","    with torch.no_grad():\n","        for i in range(maxlength):\n","            h = model(x, *h)\n","            d = model.decode(h[0])\n","            predictions.append(d.squeeze(0).tolist())\n","            probs = torch.exp(d)\n","            start = torch.distributions.categorical.Categorical(probs).sample()\n","            l.append(start.item())\n","            if start.item() == EOS_IX:\n","                break\n","            start = start.unsqueeze(-1).to(device)\n","    return code2string(l), predictions\n","string, predictions = generate(model, \"x\", 100)\n","\n","import datetime\n","torch.save(model.state_dict(), \"./models/gru-model.pth\")\n","\n","model = GRU(*args, **kwargs)\n","model.load_state_dict(torch.load(PATH))\n","model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GA_LCyatsRL5"},"source":["En pratique, les GRU et les LSTM permettent d’obtenir des résultats comparables. L’intérêt des GRU par rapport aux LSTM étant le temps d’exécution qui est plus rapide puisque moins de paramètres doivent être calculés"]},{"cell_type":"markdown","metadata":{"id":"qEVEJu6Ksz-T"},"source":["# 3. Beam-search"]},{"cell_type":"code","metadata":{"id":"CKm19rU_sSCI"},"source":["def beam_search_decoder(predictions, top_k = 3):\n","    output_sequences = [([], 0)]\n","    for token_probs in predictions:\n","        new_sequences = []\n","    \n","        for old_seq, old_score in output_sequences:\n","            for char_index in range(len(token_probs)):\n","                new_seq = old_seq + [char_index]\n","                new_score = old_score + token_probs[char_index]\n","                new_sequences.append((new_seq, new_score))\n","                \n","        output_sequences = sorted(new_sequences, key = lambda val: val[1], reverse = True)\n","        output_sequences = output_sequences[:top_k]\n","    return output_sequences\n","\n","    \n","seqeunces = beam_search_decoder(predictions, top_k = 5)\n","code2string(seqeunces[0][0])"],"execution_count":null,"outputs":[]}]}