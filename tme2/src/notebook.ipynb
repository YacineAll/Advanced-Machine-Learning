{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tp1 import mse, linear\n",
    "from tp2 import torch, Housing_data, Net\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mse = MSE()\n",
    "#linear = Linear()\n",
    "dataset  = Housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(dataloader, parameters, epsilon=1e-3, n_iter=int(1e2), tag='SGD'):\n",
    "    writer = SummaryWriter(log_dir=f'../log_dir/{tag}')\n",
    "    losses = []\n",
    "        \n",
    "    w, b  = parameters\n",
    "    \n",
    "    for epoch in range(n_iter):\n",
    "        epoch_loss = []\n",
    "        for X, y in dataloader:\n",
    "            y_pred = linear(X,w,b)\n",
    "    \n",
    "            loss = mse(y_pred, y)\n",
    "            epoch_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                w  -= w.grad*epsilon\n",
    "                b  -= b.grad*epsilon\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "        \n",
    "        epoch_loss = np.mean(epoch_loss)\n",
    "        losses.append(epoch_loss)\n",
    "        writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "        print(f'Epoch {epoch} ==> Loss: {epoch_loss}')\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feature = 13\n",
    "\n",
    "w = torch.normal(0, 1/np.sqrt(n_feature), size=(n_feature, 1), requires_grad=True, dtype=torch.float64)\n",
    "b = torch.randn(1, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "losses = SGD(dataloader, (w,b), epsilon=1e-4, n_iter=int(1e3), tag='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "w = torch.normal(0, 1/np.sqrt(n_feature), size=(n_feature, 1), requires_grad=True, dtype=torch.float64)\n",
    "b = torch.randn(1, dtype=torch.float64, requires_grad=True)\n",
    "\n",
    "\n",
    "losses = SGD(dataloader, (w,b), epsilon=1e-3, n_iter=int(1e3), tag='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=True)\n",
    "losses = SGD(dataloader, (w,b), epsilon=1e-3, n_iter=int(1e2), tag='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/mnist'\n",
    "\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(path, train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(path, train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl= Net((28*28,49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-2\n",
    "mdl = mdl.train()\n",
    "optim = torch.optim.Adam(params=mdl.parameters(),lr=EPS) ## on optimise selon w et b, lr : pas de gradient\n",
    "optim.zero_grad()\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.43491968353674104 ======> Epoch: 0\n",
      "Loss: 0.4090412420186915 ======> Epoch: 1\n",
      "Loss: 0.40206656368302385 ======> Epoch: 2\n",
      "Loss: 0.393080393960481 ======> Epoch: 3\n",
      "Loss: 0.385962201524645 ======> Epoch: 4\n",
      "Loss: 0.3848454639601555 ======> Epoch: 5\n",
      "Loss: 0.3842916318030754 ======> Epoch: 6\n",
      "Loss: 0.3840862128144897 ======> Epoch: 7\n",
      "Loss: 0.3841717267976895 ======> Epoch: 8\n",
      "Loss: 0.38394329962191553 ======> Epoch: 9\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    losses = []\n",
    "    for x,_ in train_loader:\n",
    "        x = x.reshape(x.shape[0], x.shape[2]*x.shape[3])\n",
    "        \n",
    "        xhat = mdl(x)\n",
    "        \n",
    "        loss = criterion(xhat, x)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()           \n",
    "        optim.zero_grad()\n",
    "        \n",
    "    print(f'Loss: {np.mean(losses)} ======> Epoch: {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3828071653842926 ======> Epoch: 9\n",
      "Loss: 0.38197675347328186 ======> Epoch: 9\n",
      "Loss: 0.38091859221458435 ======> Epoch: 9\n",
      "Loss: 0.3836555778980255 ======> Epoch: 9\n",
      "Loss: 0.37731513381004333 ======> Epoch: 9\n",
      "Loss: 0.38242045044898987 ======> Epoch: 9\n",
      "Loss: 0.37346962094306946 ======> Epoch: 9\n",
      "Loss: 0.38179969787597656 ======> Epoch: 9\n",
      "Loss: 0.38079744577407837 ======> Epoch: 9\n",
      "Loss: 0.37647148966789246 ======> Epoch: 9\n"
     ]
    }
   ],
   "source": [
    "for x,_ in test_loader:\n",
    "    x = x.reshape(x.shape[0], x.shape[2]*x.shape[3])\n",
    "        \n",
    "    xhat = mdl(x)\n",
    "        \n",
    "    loss = criterion(xhat, x)        \n",
    "        \n",
    "    print(f'Loss: {loss.item()} ======> Epoch: {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bita4774d6f44b14c908c5f5fa0bfb95dd2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
