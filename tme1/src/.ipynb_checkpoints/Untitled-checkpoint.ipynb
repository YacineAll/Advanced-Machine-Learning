{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#from tp1_descente import *\n",
    "from tp1 import MSE, Linear, Context\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(50, 13, requires_grad=True)\n",
    "y = torch.randn(50, 3)\n",
    "\n",
    "\n",
    "# Les paramètres du modèle à optimiser\n",
    "w = torch.randn(13, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = Linear.apply\n",
    "mse = MSE.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itérations 0: loss 40.61069107055664\n",
      "Itérations 1: loss 38.76583480834961\n",
      "Itérations 2: loss 37.02099609375\n",
      "Itérations 3: loss 35.37031936645508\n",
      "Itérations 4: loss 33.80832290649414\n",
      "Itérations 5: loss 32.32985305786133\n",
      "Itérations 6: loss 30.930072784423828\n",
      "Itérations 7: loss 29.604448318481445\n",
      "Itérations 8: loss 28.34870719909668\n",
      "Itérations 9: loss 27.15884780883789\n",
      "Itérations 10: loss 26.03110122680664\n",
      "Itérations 11: loss 24.961933135986328\n",
      "Itérations 12: loss 23.94803810119629\n",
      "Itérations 13: loss 22.986268997192383\n",
      "Itérations 14: loss 22.07368278503418\n",
      "Itérations 15: loss 21.20754623413086\n",
      "Itérations 16: loss 20.385236740112305\n",
      "Itérations 17: loss 19.604324340820312\n",
      "Itérations 18: loss 18.862504959106445\n",
      "Itérations 19: loss 18.157615661621094\n",
      "Itérations 20: loss 17.487627029418945\n",
      "Itérations 21: loss 16.850618362426758\n",
      "Itérations 22: loss 16.244787216186523\n",
      "Itérations 23: loss 15.668429374694824\n",
      "Itérations 24: loss 15.119951248168945\n",
      "Itérations 25: loss 14.597850799560547\n",
      "Itérations 26: loss 14.100692749023438\n",
      "Itérations 27: loss 13.62716293334961\n",
      "Itérations 28: loss 13.17597770690918\n",
      "Itérations 29: loss 12.745960235595703\n",
      "Itérations 30: loss 12.33598804473877\n",
      "Itérations 31: loss 11.945003509521484\n",
      "Itérations 32: loss 11.572010040283203\n",
      "Itérations 33: loss 11.216070175170898\n",
      "Itérations 34: loss 10.876294136047363\n",
      "Itérations 35: loss 10.55184268951416\n",
      "Itérations 36: loss 10.241927146911621\n",
      "Itérations 37: loss 9.945805549621582\n",
      "Itérations 38: loss 9.662766456604004\n",
      "Itérations 39: loss 9.39215087890625\n",
      "Itérations 40: loss 9.13332462310791\n",
      "Itérations 41: loss 8.885696411132812\n",
      "Itérations 42: loss 8.64870548248291\n",
      "Itérations 43: loss 8.421819686889648\n",
      "Itérations 44: loss 8.204537391662598\n",
      "Itérations 45: loss 7.996387958526611\n",
      "Itérations 46: loss 7.79691743850708\n",
      "Itérations 47: loss 7.605705261230469\n",
      "Itérations 48: loss 7.422349452972412\n",
      "Itérations 49: loss 7.246466636657715\n",
      "Itérations 50: loss 7.077702045440674\n",
      "Itérations 51: loss 6.915712356567383\n",
      "Itérations 52: loss 6.76017427444458\n",
      "Itérations 53: loss 6.61078405380249\n",
      "Itérations 54: loss 6.467251300811768\n",
      "Itérations 55: loss 6.32930326461792\n",
      "Itérations 56: loss 6.196678161621094\n",
      "Itérations 57: loss 6.069129467010498\n",
      "Itérations 58: loss 5.946423053741455\n",
      "Itérations 59: loss 5.828341960906982\n",
      "Itérations 60: loss 5.714670181274414\n",
      "Itérations 61: loss 5.605212211608887\n",
      "Itérations 62: loss 5.4997758865356445\n",
      "Itérations 63: loss 5.398182392120361\n",
      "Itérations 64: loss 5.300262928009033\n",
      "Itérations 65: loss 5.205852508544922\n",
      "Itérations 66: loss 5.114799499511719\n",
      "Itérations 67: loss 5.026956081390381\n",
      "Itérations 68: loss 4.9421844482421875\n",
      "Itérations 69: loss 4.860352039337158\n",
      "Itérations 70: loss 4.781332969665527\n",
      "Itérations 71: loss 4.705008029937744\n",
      "Itérations 72: loss 4.631263256072998\n",
      "Itérations 73: loss 4.559991359710693\n",
      "Itérations 74: loss 4.491087913513184\n",
      "Itérations 75: loss 4.424455165863037\n",
      "Itérations 76: loss 4.360002040863037\n",
      "Itérations 77: loss 4.297637462615967\n",
      "Itérations 78: loss 4.237276077270508\n",
      "Itérations 79: loss 4.1788411140441895\n",
      "Itérations 80: loss 4.122250556945801\n",
      "Itérations 81: loss 4.067436695098877\n",
      "Itérations 82: loss 4.01432466506958\n",
      "Itérations 83: loss 3.9628498554229736\n",
      "Itérations 84: loss 3.9129488468170166\n",
      "Itérations 85: loss 3.8645622730255127\n",
      "Itérations 86: loss 3.8176281452178955\n",
      "Itérations 87: loss 3.772095203399658\n",
      "Itérations 88: loss 3.7279086112976074\n",
      "Itérations 89: loss 3.6850197315216064\n",
      "Itérations 90: loss 3.643378257751465\n",
      "Itérations 91: loss 3.6029391288757324\n",
      "Itérations 92: loss 3.5636579990386963\n",
      "Itérations 93: loss 3.5254933834075928\n",
      "Itérations 94: loss 3.488403558731079\n",
      "Itérations 95: loss 3.4523515701293945\n",
      "Itérations 96: loss 3.4173007011413574\n",
      "Itérations 97: loss 3.383213520050049\n",
      "Itérations 98: loss 3.3500587940216064\n",
      "Itérations 99: loss 3.3178036212921143\n"
     ]
    }
   ],
   "source": [
    "for n_iter in range(100):\n",
    "    ##  TODO:  Calcul du forward (loss)\n",
    "\n",
    "    # `loss` doit correspondre au coût MSE calculé à cette itération\n",
    "    # on peut visualiser avec\n",
    "    # tensorboard --logdir runs/\n",
    "    y_hat = linear(x, w, b)\n",
    "    loss = mse(y_hat, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    writer.add_scalar('Loss/train', loss, n_iter)\n",
    "    # Sortie directe\n",
    "    print(f\"Itérations {n_iter}: loss {loss}\")\n",
    "        \n",
    "    # Calcul du backward (grad_w, grad_b)\n",
    "    grad_x, grad_w, grad_b = x.grad, w.grad, b.grad\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ## Mise à jour des paramètres du modèle\n",
    "        w -=  0.01 * grad_w\n",
    "        b -=  0.01 * grad_b\n",
    "    \n",
    "    #w.requires_grad_(True)\n",
    "    #b.requires_grad_(True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bita4774d6f44b14c908c5f5fa0bfb95dd2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
